{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from clearml import Dataset\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн предобработки данных:\n",
    "1) Определение характеристик данных: типов данных\n",
    "2) сведение к бинарной классификации\n",
    "3) Очистка данных: удаление дубликатов, обработка пропущенных значений: k-NN Imputer для численных, модальную для категориальных\n",
    "4) Детекция выбросов Z-score\n",
    "5) Кодирование категориальных переменных: one-hot для номинальных; label для порядковых;\n",
    "6) MinMax scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого датасета из списка используем пайплайн предобработки.\n",
    "\n",
    "Если необходимо точное воспроезвидение экспериментов из статьи, то необходима более тонкая предобработка. Поэтому была выбрана стратегия общей обработки данных для возможности оценивать различные методы на одинаковых датасетах. \n",
    "\n",
    "Сведение к бинарной классификации выбрано для возможности сравнивать методы, так как не все методы могут работать с мультиклассовостью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_project = 'Smote Test Bench'\n",
    "\n",
    "datasets_config = {\n",
    "'Adult': '77e07677143e49a39b4e4f4303099dde',\n",
    "'Forest coverage': 'eae8452f680048eb81e62021ad94a151',\n",
    "'Haberman':'b32930d5c70e48e5a38ca75d0e6ed632',\n",
    "'Ionosphere':'f0c4d8df1c5443fcbd54fc7bc5d77ddc',\n",
    "'Mammography':'23f0b97e9adc4203829fbf9b9282ebca',\n",
    "'Oil':'e528061a1d304e5ab313f9e6ad80e2d1',\n",
    "'Phoneme':'aef842d63d154b13a02601e543fe8baf', # +\n",
    "'Pima diabetes':'18a64325a8304b5290c70a06b2c1cb68',\n",
    "'Satimage':'60d6c0e2e51b43929257b113e742f96f',\n",
    "'Vehicle':'a0dc9a57c5cb492f8b4cec206d64365b',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с новым датасетом: \n",
    "1) Сначала датасет загружается на ClearML\n",
    "2) Добавляется в datasets_config название и айди датасета\n",
    "3) Предобрабатывается и добавляется новой версией к старому датасету\n",
    "4) Обработанный датасет добавляется в configs/datasets.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(datasets_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataset(dataset_name: str, max_workers: int = 8):\n",
    "    dataset_id = datasets_config[dataset_name]\n",
    "\n",
    "    if not dataset_id:\n",
    "        raise ValueError(\n",
    "            f\"Dataset ID not found for '{dataset_name}'. \"\n",
    "            f\"Check datasets.yaml configuration.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        dataset = Dataset.get(dataset_id=dataset_id)\n",
    "        local_path = dataset.get_local_copy(max_workers=max_workers)\n",
    "        data = pd.read_csv(f\"{local_path}/{dataset_name}.csv\")\n",
    "\n",
    "        metadata = dataset.get_metadata()\n",
    "        return data, metadata\n",
    "\n",
    "    except Exception as e:\n",
    "        print('ai')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_imputer(X_clean, numerical_cols, categorical_cols):\n",
    "    imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    X_numerical = X_clean[numerical_cols].copy()\n",
    "    X_imputed = imputer.fit_transform(X_numerical)\n",
    "    X_clean[numerical_cols] = X_imputed\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        mode_value = X_clean[col].mode()[0]\n",
    "        X_clean[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "    print(f\"After imputation - Missing values: {X_clean.isnull().sum().sum()}\")\n",
    "\n",
    "    return X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(X, y, continuous_features):\n",
    "    outlier_mask = np.ones(len(X), dtype=bool)\n",
    "    # Z-score \n",
    "    for col in continuous_features:\n",
    "        z_scores = np.abs(stats.zscore(X[col]))\n",
    "        outlier_mask &= z_scores < 3\n",
    "\n",
    "    if not np.all(outlier_mask):\n",
    "        X_processed = X[outlier_mask]\n",
    "        y_processed = y[outlier_mask]\n",
    "        return X_processed, y_processed\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous(X, numeric_cols):\n",
    "    threshold_ratio = 0.1   \n",
    "    con_cols = []\n",
    "    for col in numeric_cols:\n",
    "        unique = X[col].nunique()\n",
    "        ratio = unique / len(X)\n",
    "        if ratio > threshold_ratio:\n",
    "            con_cols.append(col)\n",
    "    \n",
    "    return con_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Phoneme Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Aa     Ao    Dcl     Iy     Sh   Class\n",
      "0     1.240  0.875 -0.205 -0.078  0.067       0\n",
      "1     0.268  1.352  1.035 -0.332  0.217       0\n",
      "2     1.567  0.867  1.300  1.041  0.559       0\n",
      "3     0.279  0.990  2.555 -0.738  0.000       0\n",
      "4     0.307  1.272  2.656 -0.946 -0.467       0\n",
      "...     ...    ...    ...    ...    ...     ...\n",
      "5399  0.254  2.392  0.689  1.828 -0.544       0\n",
      "5400  0.781  1.250  0.793  0.383  0.816       1\n",
      "5401  1.031  0.584  1.866  1.532 -0.671       1\n",
      "5402  0.150  0.933  2.363 -0.742 -0.617       0\n",
      "5403  0.137  0.714  1.350  0.972 -0.630       1\n",
      "\n",
      "[5404 rows x 6 columns] {'classes': 2, 'features': 5, 'target': 'Class', 'total_samples': 5404}\n"
     ]
    }
   ],
   "source": [
    "phoneme_data, phoneme_metadata = fetch_dataset('Phoneme')\n",
    "print(phoneme_data, phoneme_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "Aa      0\n",
      " Ao     0\n",
      " Dcl    0\n",
      " Iy     0\n",
      " Sh     0\n",
      "dtype: int64\n",
      "\n",
      "Categorical: 0, Numerical: 5, All: 5\n",
      "Continuous cols :  ['Aa', ' Ao', ' Dcl', ' Iy', ' Sh']\n"
     ]
    }
   ],
   "source": [
    "# Base view\n",
    "X_phoneme = phoneme_data.drop(' Class', axis=1)\n",
    "y_phoneme = phoneme_data[' Class']\n",
    "\n",
    "print(f\"\\nMissing values:\\n{X_phoneme.isnull().sum()}\")\n",
    "\n",
    "categorical_cols = X_phoneme.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_phoneme.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "continuous_cols = get_continuous(X_phoneme, numerical_cols)\n",
    "print(f\"\\nCategorical: {len(categorical_cols)}, Numerical: {len(numerical_cols)}, All: {phoneme_metadata['features']}\")\n",
    "\n",
    "# Требует ручной проверки\n",
    "print(\"Continuous cols : \", continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5349\n",
      "5349\n"
     ]
    }
   ],
   "source": [
    "# drop duplicates\n",
    "X_phoneme_clean = X_phoneme.drop_duplicates()\n",
    "y_phoneme_clean = y_phoneme[X_phoneme_clean.index]\n",
    "print(len(X_phoneme_clean))\n",
    "\n",
    "# drop rows with 40% missin values\n",
    "missing_threshold = 0.4\n",
    "valid_rows = (X_phoneme_clean.isnull().sum(axis=1) / X_phoneme_clean.shape[1]) < missing_threshold\n",
    "X_phoneme_clean = X_phoneme_clean[valid_rows]\n",
    "y_phoneme_clean = y_phoneme_clean[valid_rows]\n",
    "print(len(X_phoneme_clean))\n",
    "\n",
    "#print(pd.concat([X_phoneme_clean, y_phoneme_clean], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputation - Missing values: 0\n",
      "         Aa     Ao    Dcl     Iy     Sh   Class\n",
      "0     1.240  0.875 -0.205 -0.078  0.067       0\n",
      "1     0.268  1.352  1.035 -0.332  0.217       0\n",
      "2     1.567  0.867  1.300  1.041  0.559       0\n",
      "3     0.279  0.990  2.555 -0.738  0.000       0\n",
      "4     0.307  1.272  2.656 -0.946 -0.467       0\n",
      "...     ...    ...    ...    ...    ...     ...\n",
      "5194  0.254  2.392  0.689  1.828 -0.544       0\n",
      "5195  0.781  1.250  0.793  0.383  0.816       1\n",
      "5196  1.031  0.584  1.866  1.532 -0.671       1\n",
      "5197  0.150  0.933  2.363 -0.742 -0.617       0\n",
      "5198  0.137  0.714  1.350  0.972 -0.630       1\n",
      "\n",
      "[5199 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# impute missin values\n",
    "X_phoneme_clean = general_imputer(X_phoneme_clean, numerical_cols, categorical_cols)\n",
    "\n",
    "# handle outliers \n",
    "X_phoneme_clean_out, y_phoneme_clean_out = handle_outliers(X_phoneme_clean, y_phoneme_clean, continuous_cols)\n",
    "\n",
    "X_phoneme_clean_out = X_phoneme_clean_out.reset_index().drop('index', axis=1)\n",
    "y_phoneme_clean_out = y_phoneme_clean_out.reset_index().drop('index', axis=1)\n",
    "\n",
    "print(pd.concat([X_phoneme_clean_out, y_phoneme_clean_out], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5199, 5)\n",
      "After scaling - Min: 0.00, Max: 1.00\n",
      "Feature ranges check:\n",
      "      Aa   Ao   Dcl   Iy   Sh\n",
      "min  0.0  0.0   0.0  0.0  0.0\n",
      "max  1.0  1.0   1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# MinMax scale\n",
    "X_phoneme_scaled = scaler.fit_transform(X_phoneme_clean_out, y_phoneme_clean_out)\n",
    "X_phoneme_scaled = pd.DataFrame(X_phoneme_scaled, columns=X_phoneme_clean_out.columns)\n",
    "print(X_phoneme_scaled.shape)\n",
    "y_phoneme_scaled = y_phoneme_clean_out\n",
    "\n",
    "# Verify scaling\n",
    "print(f\"After scaling - Min: {X_phoneme_scaled.min().min():.2f}, Max: {X_phoneme_scaled.max().max():.2f}\")\n",
    "print(f\"Feature ranges check:\\n{X_phoneme_scaled.describe().loc[['min', 'max']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_data_new = pd.concat([X_phoneme_scaled, y_phoneme_scaled], axis=1)\n",
    "\n",
    "dataset_name = 'Phoneme'\n",
    "dataset_path = f'{dataset_name}.csv'\n",
    "phoneme_data_new.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: https://app.clear.ml/projects/1aa8394c881d42449a51ab796db605dc/experiments/6128c53b1b4f400c9abe6ce4469549ff/output/log\n",
      "ClearML dataset page: https://app.clear.ml/datasets/simple/1aa8394c881d42449a51ab796db605dc/experiments/6128c53b1b4f400c9abe6ce4469549ff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not repair dependency graph. Error is: 'NoneType' object has no attribute 'values'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending uploads, starting dataset upload to https://files.clear.ml\n",
      "Uploading dataset changes (1 files compressed to 137.21 KiB) to https://files.clear.ml\n",
      "File compression and upload completed: total size 137.21 KiB, 1 chunk(s) stored (average size 137.21 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.create(dataset_name=dataset_name,\n",
    "                         dataset_project=dataset_project,\n",
    "                         parent_datasets=[datasets_config[dataset_name]]) \n",
    "\n",
    "dataset.sync_folder(\n",
    "    local_path=dataset_path\n",
    ")\n",
    "\n",
    "dataset.finalize(auto_upload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass   fnlwgt   education   education-num  \\\n",
      "0       39          State-gov    77516   Bachelors              13   \n",
      "1       50   Self-emp-not-inc    83311   Bachelors              13   \n",
      "2       38            Private   215646     HS-grad               9   \n",
      "3       53            Private   234721        11th               7   \n",
      "4       28            Private   338409   Bachelors              13   \n",
      "...    ...                ...      ...         ...             ...   \n",
      "48837   39            Private   215419   Bachelors              13   \n",
      "48838   64                  ?   321403     HS-grad               9   \n",
      "48839   38            Private   374983   Bachelors              13   \n",
      "48840   44            Private    83891   Bachelors              13   \n",
      "48841   35       Self-emp-inc   182148   Bachelors              13   \n",
      "\n",
      "            martial-status          occupation     relationship  \\\n",
      "0            Never-married        Adm-clerical    Not-in-family   \n",
      "1       Married-civ-spouse     Exec-managerial          Husband   \n",
      "2                 Divorced   Handlers-cleaners    Not-in-family   \n",
      "3       Married-civ-spouse   Handlers-cleaners          Husband   \n",
      "4       Married-civ-spouse      Prof-specialty             Wife   \n",
      "...                    ...                 ...              ...   \n",
      "48837             Divorced      Prof-specialty    Not-in-family   \n",
      "48838              Widowed                   ?   Other-relative   \n",
      "48839   Married-civ-spouse      Prof-specialty          Husband   \n",
      "48840             Divorced        Adm-clerical        Own-child   \n",
      "48841   Married-civ-spouse     Exec-managerial          Husband   \n",
      "\n",
      "                      race      sex   capital-gain   capital-loss  \\\n",
      "0                    White     Male           2174              0   \n",
      "1                    White     Male              0              0   \n",
      "2                    White     Male              0              0   \n",
      "3                    Black     Male              0              0   \n",
      "4                    Black   Female              0              0   \n",
      "...                    ...      ...            ...            ...   \n",
      "48837                White   Female              0              0   \n",
      "48838                Black     Male              0              0   \n",
      "48839                White     Male              0              0   \n",
      "48840   Asian-Pac-Islander     Male           5455              0   \n",
      "48841                White     Male              0              0   \n",
      "\n",
      "        hours-per-week  native-country    class  \n",
      "0                   40   United-States    <=50K  \n",
      "1                   13   United-States    <=50K  \n",
      "2                   40   United-States    <=50K  \n",
      "3                   40   United-States    <=50K  \n",
      "4                   40            Cuba    <=50K  \n",
      "...                ...             ...      ...  \n",
      "48837               36   United-States   <=50K.  \n",
      "48838               40   United-States   <=50K.  \n",
      "48839               50   United-States   <=50K.  \n",
      "48840               40   United-States   <=50K.  \n",
      "48841               60   United-States    >50K.  \n",
      "\n",
      "[48842 rows x 15 columns] {'classes': 2, 'features': 14, 'target': 'class', 'total_samples': 48842}\n"
     ]
    }
   ],
   "source": [
    "adult_data, adult_metadata = fetch_dataset('Adult')\n",
    "print(adult_data, adult_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haberman Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1   2   3   4\n",
      "0    30  64   1   1\n",
      "1    30  62   3   1\n",
      "2    30  65   0   1\n",
      "3    31  59   2   1\n",
      "4    31  65   4   1\n",
      "..   ..  ..  ..  ..\n",
      "301  75  62   1   1\n",
      "302  76  67   0   1\n",
      "303  77  65   3   1\n",
      "304  78  65   1   2\n",
      "305  83  58   2   2\n",
      "\n",
      "[306 rows x 4 columns] {'classes': 2, 'features': 3, 'target': '4', 'total_samples': 306}\n"
     ]
    }
   ],
   "source": [
    "haberman_data, haberman_metadata = fetch_dataset('Haberman')\n",
    "print(haberman_data, haberman_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a01  a02      a03      a04      a05      a06      a07      a08      a09  \\\n",
      "0      1    0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
      "1      1    0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
      "2      1    0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
      "3      1    0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
      "4      1    0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
      "..   ...  ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "346    1    0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
      "347    1    0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
      "348    1    0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
      "349    1    0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
      "350    1    0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
      "\n",
      "         a10  ...      a26      a27      a28      a29      a30      a31  \\\n",
      "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
      "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
      "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
      "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
      "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
      "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
      "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
      "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
      "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
      "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
      "\n",
      "         a32      a33      a34  target  \n",
      "0   -0.54487  0.18641 -0.45300       g  \n",
      "1   -0.06288 -0.13738 -0.02447       b  \n",
      "2   -0.24180  0.56045 -0.38238       g  \n",
      "3    1.00000 -0.32382  1.00000       b  \n",
      "4   -0.59573 -0.04608 -0.65697       g  \n",
      "..       ...      ...      ...     ...  \n",
      "346 -0.10714  0.90546 -0.04307       g  \n",
      "347 -0.00035  0.91483  0.04712       g  \n",
      "348  0.00442  0.92697 -0.00577       g  \n",
      "349 -0.03757  0.87403 -0.16243       g  \n",
      "350 -0.06678  0.85764 -0.06151       g  \n",
      "\n",
      "[351 rows x 35 columns] {'classes': 2, 'features': 34, 'target': 'target', 'total_samples': 351}\n"
     ]
    }
   ],
   "source": [
    "Ionosphere_data, Ionosphere_metadata = fetch_dataset('Ionosphere')\n",
    "print(Ionosphere_data, Ionosphere_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest_coverage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0            2596      51      3                               258   \n",
      "1            2590      56      2                               212   \n",
      "2            2804     139      9                               268   \n",
      "3            2785     155     18                               242   \n",
      "4            2595      45      2                               153   \n",
      "...           ...     ...    ...                               ...   \n",
      "581007       2396     153     20                                85   \n",
      "581008       2391     152     19                                67   \n",
      "581009       2386     159     17                                60   \n",
      "581010       2384     170     15                                60   \n",
      "581011       2383     165     13                                60   \n",
      "\n",
      "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                                    0                              510   \n",
      "1                                   -6                              390   \n",
      "2                                   65                             3180   \n",
      "3                                  118                             3090   \n",
      "4                                   -1                              391   \n",
      "...                                ...                              ...   \n",
      "581007                              17                              108   \n",
      "581008                              12                               95   \n",
      "581009                               7                               90   \n",
      "581010                               5                               90   \n",
      "581011                               4                               67   \n",
      "\n",
      "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
      "0                 221             232            148   \n",
      "1                 220             235            151   \n",
      "2                 234             238            135   \n",
      "3                 238             238            122   \n",
      "4                 220             234            150   \n",
      "...               ...             ...            ...   \n",
      "581007            240             237            118   \n",
      "581008            240             237            119   \n",
      "581009            236             241            130   \n",
      "581010            230             245            143   \n",
      "581011            231             244            141   \n",
      "\n",
      "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
      "0                                     6279  ...            0            0   \n",
      "1                                     6225  ...            0            0   \n",
      "2                                     6121  ...            0            0   \n",
      "3                                     6211  ...            0            0   \n",
      "4                                     6172  ...            0            0   \n",
      "...                                    ...  ...          ...          ...   \n",
      "581007                                 837  ...            0            0   \n",
      "581008                                 845  ...            0            0   \n",
      "581009                                 854  ...            0            0   \n",
      "581010                                 864  ...            0            0   \n",
      "581011                                 875  ...            0            0   \n",
      "\n",
      "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
      "0                 0            0            0            0            0   \n",
      "1                 0            0            0            0            0   \n",
      "2                 0            0            0            0            0   \n",
      "3                 0            0            0            0            0   \n",
      "4                 0            0            0            0            0   \n",
      "...             ...          ...          ...          ...          ...   \n",
      "581007            0            0            0            0            0   \n",
      "581008            0            0            0            0            0   \n",
      "581009            0            0            0            0            0   \n",
      "581010            0            0            0            0            0   \n",
      "581011            0            0            0            0            0   \n",
      "\n",
      "        Soil_Type39  Soil_Type40   class  \n",
      "0                 0            0       5  \n",
      "1                 0            0       5  \n",
      "2                 0            0       2  \n",
      "3                 0            0       2  \n",
      "4                 0            0       5  \n",
      "...             ...          ...     ...  \n",
      "581007            0            0       3  \n",
      "581008            0            0       3  \n",
      "581009            0            0       3  \n",
      "581010            0            0       3  \n",
      "581011            0            0       3  \n",
      "\n",
      "[581012 rows x 55 columns] {'classes': 7, 'features': 54, 'target': 'class', 'total_samples': 581012}\n"
     ]
    }
   ],
   "source": [
    "Forest_coverage_data, Forest_coverage_metadata = fetch_dataset('Forest coverage')\n",
    "print(Forest_coverage_data, Forest_coverage_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
